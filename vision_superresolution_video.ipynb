{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Parag-dwn/VIdeo-Enhancement/blob/main/vision_superresolution_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74e3c567",
      "metadata": {
        "tags": [],
        "id": "74e3c567"
      },
      "source": [
        "# Video Super Resolution with OpenVINO™\n",
        "Super Resolution is the process of enhancing the quality of an image by increasing the pixel count using deep learning. This notebook applies Single Image Super Resolution (SISR) to frames in a 360p (480×360) video in 360p resolution. A model called [single-image-super-resolution-1032](https://docs.openvino.ai/2023.0/omz_models_model_single_image_super_resolution_1032.html), which is available in Open Model Zoo, is used in this tutorial. It is based on the research paper cited below.\n",
        "\n",
        "> **NOTE**: The Single Image Super Resolution (SISR) model used in this demo is not optimized for a video. Results may vary depending on the video.\n",
        "\n",
        "#### Table of contents:\n",
        "- [Preparation](#Preparation)\n",
        "    - [Install requirements](#Install-requirements)\n",
        "    - [Imports](#Imports)\n",
        "    - [Settings](#Settings)\n",
        "        - [Select inference device](#Select-inference-device)\n",
        "    - [Functions](#Functions)\n",
        "- [Load the Superresolution Model](#Load-the-Superresolution-Model)\n",
        "- [Superresolution on Video](#Superresolution-on-Video)\n",
        "    - [Settings](#Settings)\n",
        "    - [Download and Prepare Video](#Download-and-Prepare-Video)\n",
        "    - [Do Inference](#Do-Inference)\n",
        "    - [Show Side-by-Side Video of Bicubic and Superresolution Version](#Show-Side-by-Side-Video-of-Bicubic-and-Superresolution-Version)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4026645b",
      "metadata": {
        "id": "4026645b"
      },
      "source": [
        "## Preparation\n",
        "[back to top ⬆️](#Table-of-contents:)\n",
        "\n",
        "### Install requirements\n",
        "[back to top ⬆️](#Table-of-contents:)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9f658ba9",
      "metadata": {
        "id": "9f658ba9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d1131a3-7005-447b-abdc-4985a70d9a98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.5/37.5 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -q \"openvino>=2023.1.0\"\n",
        "%pip install -q opencv-python\n",
        "%pip install -q \"pytube>=12.1.0\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7e726e7",
      "metadata": {
        "id": "b7e726e7"
      },
      "source": [
        "### Imports\n",
        "[back to top ⬆️](#Table-of-contents:)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4ef55816",
      "metadata": {
        "tags": [],
        "id": "4ef55816"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from IPython.display import (\n",
        "    HTML,\n",
        "    FileLink,\n",
        "    Pretty,\n",
        "    ProgressBar,\n",
        "    Video,\n",
        "    clear_output,\n",
        "    display,\n",
        ")\n",
        "import openvino as ov\n",
        "from pytube import YouTube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c6824d93",
      "metadata": {
        "id": "c6824d93"
      },
      "outputs": [],
      "source": [
        "# Define a download file helper function\n",
        "def download_file(url: str, path: Path) -> None:\n",
        "    \"\"\"Download file.\"\"\"\n",
        "    import urllib.request\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    urllib.request.urlretrieve(url, path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4891215e",
      "metadata": {
        "id": "4891215e"
      },
      "source": [
        "### Settings\n",
        "[back to top ⬆️](#Table-of-contents:)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "275aab16-ab78-4586-a494-64a22ee31a2b",
      "metadata": {
        "id": "275aab16-ab78-4586-a494-64a22ee31a2b"
      },
      "source": [
        "#### Select inference device\n",
        "[back to top ⬆️](#Table-of-contents:)\n",
        "\n",
        "select device from dropdown list for running inference using OpenVINO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bce615e3-486f-41bb-b769-a50f97cc3f59",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [
          "hide-input"
        ],
        "id": "bce615e3-486f-41bb-b769-a50f97cc3f59",
        "outputId": "c31660ec-da16-4b4a-d709-1c53d6382151",
        "colab": {
          "referenced_widgets": [
            "bc787c173d7b46cd8da509e523898d3d",
            "8b371c0b760042fba0022228b38bcf9c",
            "d0db606537754c1ab1516d6a6c2a9dc8"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Device:', index=1, options=('CPU', 'AUTO'), value='AUTO')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc787c173d7b46cd8da509e523898d3d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import ipywidgets as widgets\n",
        "\n",
        "core = ov.Core()\n",
        "device = widgets.Dropdown(\n",
        "    options=core.available_devices + [\"AUTO\"],\n",
        "    value='AUTO',\n",
        "    description='Device:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "582d9cde",
      "metadata": {
        "tags": [],
        "id": "582d9cde"
      },
      "outputs": [],
      "source": [
        "# 1032: 4x superresolution, 1033: 3x superresolution\n",
        "model_name = 'single-image-super-resolution-1032'\n",
        "\n",
        "base_model_dir = Path('./model').expanduser()\n",
        "\n",
        "model_xml_name = f'{model_name}.xml'\n",
        "model_bin_name = f'{model_name}.bin'\n",
        "\n",
        "model_xml_path = base_model_dir / model_xml_name\n",
        "model_bin_path = base_model_dir / model_bin_name\n",
        "\n",
        "if not model_xml_path.exists():\n",
        "    base_url = f'https://storage.openvinotoolkit.org/repositories/open_model_zoo/2023.0/models_bin/1/{model_name}/FP16/'\n",
        "    model_xml_url = base_url + model_xml_name\n",
        "    model_bin_url = base_url + model_bin_name\n",
        "\n",
        "    download_file(model_xml_url, model_xml_path)\n",
        "    download_file(model_bin_url, model_bin_path)\n",
        "else:\n",
        "    print(f'{model_name} already downloaded to {base_model_dir}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdd4c452",
      "metadata": {
        "id": "cdd4c452"
      },
      "source": [
        "### Functions\n",
        "[back to top ⬆️](#Table-of-contents:)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4818ca56",
      "metadata": {
        "tags": [],
        "id": "4818ca56"
      },
      "outputs": [],
      "source": [
        "def convert_result_to_image(result) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Convert network result of floating point numbers to image with integer\n",
        "    values from 0-255. Values outside this range are clipped to 0 and 255.\n",
        "\n",
        "    :param result: a single superresolution network result in N,C,H,W shape\n",
        "    \"\"\"\n",
        "    result = result.squeeze(0).transpose(1, 2, 0)\n",
        "    result *= 255\n",
        "    result[result < 0] = 0\n",
        "    result[result > 255] = 255\n",
        "    result = result.astype(np.uint8)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b8dc8ea",
      "metadata": {
        "id": "8b8dc8ea"
      },
      "source": [
        "## Load the Superresolution Model\n",
        "[back to top ⬆️](#Table-of-contents:)\n",
        "\n",
        "Load the model in OpenVINO Runtime with `core.read_model` and compile it for the specified device with `core.compile_model`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c8fee7d4",
      "metadata": {
        "tags": [],
        "id": "c8fee7d4"
      },
      "outputs": [],
      "source": [
        "core = ov.Core()\n",
        "model = core.read_model(model=model_xml_path)\n",
        "compiled_model = core.compile_model(model=model, device_name=device.value)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d897ad82",
      "metadata": {
        "id": "d897ad82"
      },
      "source": [
        "Get information about network inputs and outputs. The Super Resolution model expects two inputs: the input image and a bicubic interpolation of the input image to the target size of 1920x1080. It returns the super resolution version of the image in 1920x1080."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b23a5d80",
      "metadata": {
        "tags": [],
        "id": "b23a5d80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73ea41dd-9224-43ca-c38b-5e49bcaca2a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The network expects inputs with a width of 480, height of 270\n",
            "The network returns images with a width of 1920, height of 1080\n",
            "The image sides are upsampled by a factor of 4. The new image is 16 times as large as the original image\n"
          ]
        }
      ],
      "source": [
        "# Network inputs and outputs are dictionaries. Get the keys for the\n",
        "# dictionaries.\n",
        "original_image_key, bicubic_image_key = compiled_model.inputs\n",
        "output_key = compiled_model.output(0)\n",
        "\n",
        "# Get the expected input and target shape. The `.dims[2:]` function returns the height\n",
        "# and width.The `resize` function of  OpenCV expects the shape as (width, height),\n",
        "# so reverse the shape with `[::-1]` and convert it to a tuple.\n",
        "input_height, input_width = list(original_image_key.shape)[2:]\n",
        "target_height, target_width = list(bicubic_image_key.shape)[2:]\n",
        "\n",
        "upsample_factor = int(target_height / input_height)\n",
        "\n",
        "print(f\"The network expects inputs with a width of {input_width}, \" f\"height of {input_height}\")\n",
        "print(f\"The network returns images with a width of {target_width}, \" f\"height of {target_height}\")\n",
        "\n",
        "print(\n",
        "    f\"The image sides are upsampled by a factor of {upsample_factor}. \"\n",
        "    f\"The new image is {upsample_factor**2} times as large as the \"\n",
        "    \"original image\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "564fc343",
      "metadata": {
        "id": "564fc343"
      },
      "source": [
        "## Superresolution on Video\n",
        "[back to top ⬆️](#Table-of-contents:)\n",
        "\n",
        "Download a YouTube video with `PyTube` and enhance the video quality with superresolution.\n",
        "\n",
        "By default, only the first 100 frames of the video are processed. Change `NUM_FRAMES` in the cell below to modify this.\n",
        "\n",
        "> **NOTE**: The resulting video does not contain audio. The input video should be a landscape video and have an input resolution of 360p (640x360) for the 1032 model, or 480p (720x480) for the 1033 model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8356c7b",
      "metadata": {
        "id": "b8356c7b"
      },
      "source": [
        "### Settings\n",
        "[back to top ⬆️](#Table-of-contents:)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "af99b289",
      "metadata": {
        "tags": [],
        "test_replace": {
          "NUM_FRAMES = 100": "NUM_FRAMES = 3"
        },
        "id": "af99b289"
      },
      "outputs": [],
      "source": [
        "OUTPUT_DIR = \"output\"\n",
        "\n",
        "Path(OUTPUT_DIR).mkdir(exist_ok=True)\n",
        "# Maximum number of frames to read from the input video. Set to 0 to read all frames.\n",
        "NUM_FRAMES = 300\n",
        "# The format for saving the result videos. The `vp09` codec is slow, but widely available.\n",
        "# If you have FFMPEG installed, you can change FOURCC to `*\"THEO\"` to improve video writing speed.\n",
        "FOURCC = cv2.VideoWriter_fourcc(*\"vp09\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84a630d4",
      "metadata": {
        "id": "84a630d4"
      },
      "source": [
        "### Download and Prepare Video\n",
        "[back to top ⬆️](#Table-of-contents:)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoY_dO6fEjDC",
        "outputId": "9857ee9c-1406-4527-d1d8-623dd4065a42"
      },
      "id": "JoY_dO6fEjDC",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "76b55b9c",
      "metadata": {
        "tags": [],
        "id": "76b55b9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb770d6d-4ee8-4614-86cf-455500a050e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video test3.mp4 downloaded to output\n"
          ]
        }
      ],
      "source": [
        "# Use pytube to download a video. It downloads to the videos subdirectory.\n",
        "# You can also place a local video there and comment out the following lines\n",
        "# Use `yt.streams` to see all available streams. See the PyTube documentation\n",
        "# https://python-pytube.readthedocs.io/en/latest/api.html for advanced\n",
        "# filtering options\n",
        "! cp /content/gdrive/MyDrive/Video_assignment/test3.mp4 output/\n",
        "filename = Path('test3.mp4')\n",
        "print(f\"Video {filename} downloaded to {OUTPUT_DIR}\")\n",
        "\n",
        "# Create Path objects for the input video and the resulting videos.\n",
        "video_path = Path('/content/output/test3.mp4')\n",
        "\n",
        "# Path names for the result videos.\n",
        "superres_video_path = Path(f\"{OUTPUT_DIR}/{video_path.stem}_superres.mp4\")\n",
        "bicubic_video_path = Path(f\"{OUTPUT_DIR}/{video_path.stem}_bicubic.mp4\")\n",
        "comparison_video_path = Path(f\"{OUTPUT_DIR}/{video_path.stem}_superres_comparison.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "678b6cf5",
      "metadata": {
        "tags": [],
        "id": "678b6cf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66997b2f-86ee-453a-c6a1-dc24c89aca81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input video has a frame width of 1280, frame height of 720 and runs at 30.00 fps\n"
          ]
        }
      ],
      "source": [
        "# Open the video and get the dimensions and the FPS.\n",
        "cap = cv2.VideoCapture(filename=str(video_path))\n",
        "ret, image = cap.read()\n",
        "if not ret:\n",
        "    raise ValueError(f\"The video at '{video_path}' cannot be read.\")\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "\n",
        "if NUM_FRAMES == 0:\n",
        "    total_frames = frame_count\n",
        "else:\n",
        "    total_frames = min(frame_count, NUM_FRAMES)\n",
        "\n",
        "original_frame_height, original_frame_width = image.shape[:2]\n",
        "\n",
        "cap.release()\n",
        "print(\n",
        "    f\"The input video has a frame width of {original_frame_width}, \"\n",
        "    f\"frame height of {original_frame_height} and runs at {fps:.2f} fps\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fd26468",
      "metadata": {
        "id": "6fd26468"
      },
      "source": [
        "Create a superresolution video, a bicubic video and a comparison video. The superresolution video contains the enhanced video, upsampled with superresolution, the bicubic video is the input video upsampled with bicubic interpolation, the comparison video sets the bicubic video and the superresolution side by side."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a6951656-1230-480a-a185-df603efc93d7",
      "metadata": {
        "tags": [],
        "id": "a6951656-1230-480a-a185-df603efc93d7"
      },
      "outputs": [],
      "source": [
        "superres_video = cv2.VideoWriter(\n",
        "    filename=str(superres_video_path),\n",
        "    fourcc=FOURCC,\n",
        "    fps=fps,\n",
        "    frameSize=(target_width, target_height),\n",
        ")\n",
        "bicubic_video = cv2.VideoWriter(\n",
        "    filename=str(bicubic_video_path),\n",
        "    fourcc=FOURCC,\n",
        "    fps=fps,\n",
        "    frameSize=(target_width, target_height),\n",
        ")\n",
        "comparison_video = cv2.VideoWriter(\n",
        "    filename=str(comparison_video_path),\n",
        "    fourcc=FOURCC,\n",
        "    fps=fps,\n",
        "    frameSize=(target_width * 2, target_height),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27b5c979",
      "metadata": {
        "id": "27b5c979"
      },
      "source": [
        "### Do Inference\n",
        "[back to top ⬆️](#Table-of-contents:)\n",
        "\n",
        "Read video frames and enhance them with superresolution. Save the superresolution video, the bicubic video and the comparison video to a file.\n",
        "\n",
        "The code below reads the video frame by frame. Each frame is resized and reshaped to the network input shape and upsampled with bicubic interpolation to the target shape. Both the original and the bicubic images are propagated through the network. The network result is a numpy array with floating point values, with a shape of `(1,3,1920,1080)`. This array is converted to an 8-bit image with the `(1080,1920,3)` shape and written to a `superres_video`. The bicubic image is written to a `bicubic_video` for comparison. Finally, the bicubic and result frames are combined side by side and written to a `comparison_video`. A progress bar shows the progress of the process. Both inference time and total time to process each frame are measured. That also includes inference time as well as the time it takes to process and write the video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "12ac8de5",
      "metadata": {
        "tags": [],
        "id": "12ac8de5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "84452a5c-8ff6-4dc9-e82a-d5ae3309f9a6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[============================================================] 300/300"
            ],
            "text/html": [
              "<progress style='width:60ex' max='300' value='300'></progress>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processed frame 300. Inference time: 0.57 seconds (1.76 FPS)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video's saved to output directory.\n",
            "Processed 300 frames in 2215.92 seconds. Total FPS (including video processing): 0.14. Inference FPS: 1.59.\n"
          ]
        }
      ],
      "source": [
        "start_time = time.perf_counter()\n",
        "frame_nr = 0\n",
        "total_inference_duration = 0\n",
        "\n",
        "progress_bar = ProgressBar(total=total_frames)\n",
        "progress_bar.display()\n",
        "\n",
        "cap = cv2.VideoCapture(filename=str(video_path))\n",
        "try:\n",
        "    while cap.isOpened():\n",
        "        ret, image = cap.read()\n",
        "        if not ret:\n",
        "            cap.release()\n",
        "            break\n",
        "\n",
        "        if frame_nr >= total_frames:\n",
        "            break\n",
        "\n",
        "        # Resize the input image to the network shape and convert it from (H,W,C) to\n",
        "        # (N,C,H,W).\n",
        "        resized_image = cv2.resize(src=image, dsize=(input_width, input_height))\n",
        "        input_image_original = np.expand_dims(resized_image.transpose(2, 0, 1), axis=0)\n",
        "\n",
        "        # Resize and reshape the image to the target shape with bicubic\n",
        "        # interpolation.\n",
        "        bicubic_image = cv2.resize(\n",
        "            src=image, dsize=(target_width, target_height), interpolation=cv2.INTER_CUBIC\n",
        "        )\n",
        "        input_image_bicubic = np.expand_dims(bicubic_image.transpose(2, 0, 1), axis=0)\n",
        "\n",
        "        # Do inference.\n",
        "        inference_start_time = time.perf_counter()\n",
        "        result = compiled_model(\n",
        "            {\n",
        "                original_image_key.any_name: input_image_original,\n",
        "                bicubic_image_key.any_name: input_image_bicubic,\n",
        "            }\n",
        "        )[output_key]\n",
        "        inference_stop_time = time.perf_counter()\n",
        "        inference_duration = inference_stop_time - inference_start_time\n",
        "        total_inference_duration += inference_duration\n",
        "\n",
        "        # Transform the inference result into an image.\n",
        "        result_frame = convert_result_to_image(result=result)\n",
        "\n",
        "        # Write the result image and the bicubic image to a video file.\n",
        "        superres_video.write(image=result_frame)\n",
        "        bicubic_video.write(image=bicubic_image)\n",
        "\n",
        "        stacked_frame = np.hstack((bicubic_image, result_frame))\n",
        "        comparison_video.write(image=stacked_frame)\n",
        "\n",
        "        frame_nr = frame_nr + 1\n",
        "\n",
        "        # Update the progress bar and the status message.\n",
        "        progress_bar.progress = frame_nr\n",
        "        progress_bar.update()\n",
        "        if frame_nr % 10 == 0 or frame_nr == total_frames:\n",
        "            clear_output(wait=True)\n",
        "            progress_bar.display()\n",
        "            display(\n",
        "                Pretty(\n",
        "                    f\"Processed frame {frame_nr}. Inference time: \"\n",
        "                    f\"{inference_duration:.2f} seconds \"\n",
        "                    f\"({1/inference_duration:.2f} FPS)\"\n",
        "                )\n",
        "            )\n",
        "\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Processing interrupted.\")\n",
        "finally:\n",
        "    superres_video.release()\n",
        "    bicubic_video.release()\n",
        "    comparison_video.release()\n",
        "    end_time = time.perf_counter()\n",
        "    duration = end_time - start_time\n",
        "    print(f\"Video's saved to {comparison_video_path.parent} directory.\")\n",
        "    print(\n",
        "        f\"Processed {frame_nr} frames in {duration:.2f} seconds. Total FPS \"\n",
        "        f\"(including video processing): {frame_nr/duration:.2f}. \"\n",
        "        f\"Inference FPS: {frame_nr/total_inference_duration:.2f}.\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61022f66",
      "metadata": {
        "id": "61022f66"
      },
      "source": [
        "### Show Side-by-Side Video of Bicubic and Superresolution Version\n",
        "[back to top ⬆️](#Table-of-contents:)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b32ba25d",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": [],
        "id": "b32ba25d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "16aaf78b-79f1-4a07-84c9-ae3dfff2a9e4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Showing side by side comparison. If you cannot see the video in your browser, please click on the following link to download the video<br><a href='output/test3_superres_comparison.mp4' download>output/test3_superres_comparison.mp4</a><br>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "if not comparison_video_path.exists():\n",
        "    raise ValueError(\"The comparison video does not exist.\")\n",
        "else:\n",
        "    video_link = FileLink(comparison_video_path)\n",
        "    video_link.html_link_str = \"<a href='%s' download>%s</a>\"\n",
        "    display(\n",
        "        HTML(\n",
        "            f\"Showing side by side comparison. If you cannot see the video in \"\n",
        "            \"your browser, please click on the following link to download \"\n",
        "            f\"the video<br>{video_link._repr_html_()}\"\n",
        "        )\n",
        "    )\n",
        "    display(Video(comparison_video_path, width=800, embed=True))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/output/* /content/gdrive/MyDrive/VideoEnhancement_Output"
      ],
      "metadata": {
        "id": "WKVwte-GVTgB"
      },
      "id": "WKVwte-GVTgB",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ERk_13LBBTnA"
      },
      "id": "ERk_13LBBTnA",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "bb0b397daf458ed78ef5a7e21732498aa92824cb15d3098f5341da903a887e15"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bc787c173d7b46cd8da509e523898d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "CPU",
              "AUTO"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Device:",
            "description_tooltip": null,
            "disabled": false,
            "index": 1,
            "layout": "IPY_MODEL_8b371c0b760042fba0022228b38bcf9c",
            "style": "IPY_MODEL_d0db606537754c1ab1516d6a6c2a9dc8"
          }
        },
        "8b371c0b760042fba0022228b38bcf9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0db606537754c1ab1516d6a6c2a9dc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}